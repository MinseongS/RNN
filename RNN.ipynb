{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdy_PbGcN7o-"
      },
      "source": [
        "# (1) Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08xiNTkBNtHn"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPxfqOZjN_Bd"
      },
      "source": [
        "# (2) parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g70iNCOtN7JS"
      },
      "source": [
        "sequence_length = 28\n",
        "input_size = 28\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "num_epochs = 2\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F08yHvQmOKZy"
      },
      "source": [
        "device = 'cuda'"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAwM-zBWOQ4t"
      },
      "source": [
        "# (3) data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhhEwNd_OQEH"
      },
      "source": [
        "mnist_train = dset.MNIST(\"\", train=True, transform=transforms.ToTensor(),\n",
        "                         target_transform=None, download=True)\n",
        "\n",
        "mnist_test = dset.MNIST(\"\", train=False, transform=transforms.ToTensor(),\n",
        "                        target_transform=None, download=True)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi3N3tWPgISB"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          drop_last=True)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "VCtDgp4aOlMZ",
        "outputId": "0cbec248-de10-45cf-ff32-0af9f1368e82"
      },
      "source": [
        "print(\"mnist_train 길이:\", len(mnist_train))\n",
        "print(\"mnist_test 길이:\", len(mnist_test))\n",
        "\n",
        "image, label = mnist_train.__getitem__(0)\n",
        "print(\"image data 형태:\", image.size())\n",
        "print(\"label:\", label)\n",
        "\n",
        "img = image.numpy()\n",
        "plt.title(f\"label:{label}\")\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist_train 길이: 60000\n",
            "mnist_test 길이: 10000\n",
            "image data 형태: torch.Size([1, 28, 28])\n",
            "label: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ugORR6fQEKA"
      },
      "source": [
        "# (4) Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42i84OIBP_cB"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(RNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # input tensor: (batch_size, seq_length, input_size)\n",
        "    # x: (100, 28, 28)\n",
        "    \n",
        "    # hidden state tensor: (num_layers, batch_size, hidden_size)\n",
        "    # h: (2, 100, 128)\n",
        "    h0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(device)\n",
        "    c0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(device)\n",
        "\n",
        "    # Forward propagets LSTM\n",
        "    # output tensor: (batch_size, seq_length, hidden_size)\n",
        "    # out: (100, 28, 28)\n",
        "    \n",
        "    out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "    # 28th output layer : (batch_size, hidden_size)\n",
        "    # out[:, -1, :]: (100, 128)\n",
        "\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    # y^: (batch_size, num_classes)\n",
        "    # y_pred: (100, 10)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X0GZIZvUEP2"
      },
      "source": [
        "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu8evlSIUJ79"
      },
      "source": [
        "def ComputeAccr(dloader, imodel):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for j, [imgs, labels] in enumerate(dloader):\n",
        "    # x; (batch_size, 1, seq_length, input_size) -> (batch_size, seq_length, input_size)\n",
        "    img = imgs\n",
        "    img = img.reshape(-1, sequence_length, input_size).to(device)\n",
        "\n",
        "    # y: (batch_size, num_classes)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    output = imodel(img)\n",
        "    _, output_index = torch.max(output, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (output_index == labels).sum().float()\n",
        "\n",
        "  return (100*correct/total)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWvQWS3BVOQc",
        "outputId": "09d4b7a4-0021-41b0-f2c2-8b551908bf34"
      },
      "source": [
        "print(f\"Accuracy of Test Data: {ComputeAccr(test_loader, model)}\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Test Data: 10.09000015258789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khCJuItzWH4G"
      },
      "source": [
        "# (5) loss function, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9BdRG9cVcgR"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWAmXcbZWV_k"
      },
      "source": [
        "# (6) train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDmBMdQ3WSAd",
        "outputId": "290fa053-d92f-4930-d124-e2ea0a2de41f"
      },
      "source": [
        "total_step = len(train_loader)\n",
        "for epochs in range(num_epochs):\n",
        "  for i, [imgs, labels] in enumerate(train_loader):\n",
        "    img = imgs\n",
        "    img = img.reshape(-1, sequence_length, input_size).to(device)\n",
        "\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(img)\n",
        "    loss = loss_func(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print(f\"Epoch [{epochs+1}/{num_epochs}], Step [{i+1}/{total_step}], loss: {loss.item()}, Accr: {ComputeAccr(test_loader, model)}\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/2], Step [100/600], loss: 0.05954687297344208, Accr: 97.18999481201172\n",
            "Epoch [1/2], Step [200/600], loss: 0.153119757771492, Accr: 96.97999572753906\n",
            "Epoch [1/2], Step [300/600], loss: 0.05378260463476181, Accr: 97.29999542236328\n",
            "Epoch [1/2], Step [400/600], loss: 0.06527180969715118, Accr: 97.52999877929688\n",
            "Epoch [1/2], Step [500/600], loss: 0.20690388977527618, Accr: 97.45999908447266\n",
            "Epoch [1/2], Step [600/600], loss: 0.14974823594093323, Accr: 97.73999786376953\n",
            "Epoch [2/2], Step [100/600], loss: 0.09696631133556366, Accr: 97.58999633789062\n",
            "Epoch [2/2], Step [200/600], loss: 0.011612411588430405, Accr: 97.93000030517578\n",
            "Epoch [2/2], Step [300/600], loss: 0.024327421560883522, Accr: 97.89999389648438\n",
            "Epoch [2/2], Step [400/600], loss: 0.06923641264438629, Accr: 97.98999786376953\n",
            "Epoch [2/2], Step [500/600], loss: 0.08636899292469025, Accr: 97.5199966430664\n",
            "Epoch [2/2], Step [600/600], loss: 0.17245979607105255, Accr: 97.87999725341797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXoetG20osia"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}